<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title> | Yan&#39;s Homepage</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
<script async src="https://www.googletagmanager.com/gtag/js?id=G-G4YLGPCNZD"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-G4YLGPCNZD', { 'anonymize_ip': false });
}
</script>

  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/research/">Research</a></li>
      
      <li><a href="/talk/">Talks</a></li>
      
      <li><a href="/industry/">Industry</a></li>
      
      <li><a href="/service/">Services</a></li>
      
      <li><a href="/misc/">Misc</a></li>
      
    </ul>
    <hr/>
    </nav>



<main>
<p>I have been fortunate enough to play with some interesting and challenging optimization tasks for training neural recommendation models at an industrial scale.</p>
<p>These recommenders, along with their embedding tables, easily exceed <strong>Trillion</strong> bytes in size.</p>
<p>Training at this scale creates many interesting stochastic and distributed optimization problems, and calls for usecase-dependent method development.</p>
<ul>
<li><strong>Research Intern, Facebook (Meta), Ads Ranking</strong>
<ul>
<li>Date: May 2021 - Nov 2021.</li>
<li>Mentor: <a href="https://sites.google.com/usc.edu/xiaohan">Xiaohan Wei</a>, <a href="https://www.linkedin.com/in/dhruvchoudhary/">Dhruv Choudhary</a>.</li>
<li>If you are searching for an algorithm that is memory efficient, and enjoys provable benefits over SGD for nonconvex embedding learning, check out the method (published in <a href="https://openreview.net/pdf?id=ibqTBNfJmi">ICLR 2022</a>) I developed that gives you both, while Adagrad/Adam variants give you none.</li>
</ul>
</li>
</ul>
<ul>
<li><strong>Research Intern, Bytedance, AML</strong>
<ul>
<li>Date: May 2021 - Nov 2021.</li>
<li>Mentor: <a href="https://chongw.github.io/">Chong Wang</a>.</li>
<li>I mainly work on developing training techniques that prevents degenerate learning in the deep <a href="https://arxiv.org/pdf/2007.07203.pdf">retrieval model</a>.</li>
</ul>
</li>
</ul>

</main>

  <footer>
  <script defer src="//yihui.org/js/math-code.js"></script>
<script defer src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<script defer src="//yihui.org/js/center-img.js"></script>

  
  <hr/>
  Â© <a href="https://gzliyan113.github.io">Yan Li 2022 - 2022</a> | <a href="https://scholar.google.com/citations?view_op=list_works&amp;hl=en&amp;hl=en&amp;user=wLfoeakAAAAJ">Google Scholar</a> | <a href="mailto:gzliyan113@gatech.edu">Email</a> | <a href="https://github.com/gzliyan113">Github</a> |  <a href="https://twitter.com/gzliyan113">Twitter</a> | <a href="https://www.linkedin.com/in/yan-li-151a6292/">Linkedin</a>
  
  </footer>
  </body>
</html>

